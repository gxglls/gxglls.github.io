<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>记一次linux内核软死锁分析思路</title>
    <url>/2019/10/28/%E8%AE%B0%E4%B8%80%E6%AC%A1linux%E5%86%85%E6%A0%B8%E8%BD%AF%E6%AD%BB%E9%94%81%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/</url>
    <content><![CDATA[<h4 id="故障分析："><a href="#故障分析：" class="headerlink" title="故障分析："></a>故障分析：</h4><p>  2019/10/25 下午15左右运维收到报警，dvm虚拟机10.29.5.122无法连接，对应业务为dmall-coupon-daemon.  在cmdb查看该vm仍为running状态，运维通过该vm所在的openstack宿主机查看到该vm状态为存活。此时该vm的状态为 能ping通但无法ssh登陆,系统反应缓慢。从监控数据上看到，该vm失联前内存充足，cpu无大波动，心跳戛然而止:</p><p><img src="zabbix%E7%9B%91%E6%8E%A7.png" alt><br>此时运维通过openstack管理界面查看该vm的console输出，有大量kernel log输出如下:</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[2783390.079911] NMI watchdog: BUG: soft lockup - CPU<span class="comment">#0 stuck for 23s[sh:7422]</span></span><br><span class="line">[   28.124720] Modules linked <span class="keyword">in</span>:</span><br><span class="line">[   28.125247] Supported: Yes</span><br><span class="line">[   28.125763] Modules linked <span class="keyword">in</span>:</span><br><span class="line">[   28.126277] Supported: Yes</span><br><span class="line">[   28.126774] </span><br><span class="line">[   28.127264] Pid: 1, comm: init Not tainted 3.0.101-63-xen <span class="comment">#1  </span></span><br><span class="line">[   28.127765] EIP: 0061:[&lt;c00ded0a&gt;] EFLAGS: 00000202 CPU: 0</span><br><span class="line">[   28.128002] EIP is at handle_mm_fault+0x18a/0x2b0</span><br><span class="line">[   28.128002] EAX: 0002bfc1 EBX: 00000000 ECX: 00000000 EDX: 00000000</span><br><span class="line">[   28.128002] ESI: 2bfc1067 EDI: 00000000 EBP: ebfc6200 ESP: ebc35d48</span><br><span class="line">[   28.128002]  DS: 007b ES: 007b FS: 00d8 GS: 0000 SS: e021</span><br><span class="line">[   28.128002] Process init (pid: 1, ti=ebc08000 task=ebc32ce0 task.ti=ebc34000)</span><br><span class="line">[   28.128002] Stack:</span><br><span class="line">[   28.128002]  ebfc1778 ebfc6200 00000029 0002bfc1 00000000 080efc90 ebfc2570 ebfc9e40</span><br><span class="line">[   28.128002]  ec7bd000 ebc35dfc 00000003 ebfc2570 080efc90 c0350ad4 00000029 00000100</span><br><span class="line">[   28.128002]  00000008 00000003 ebfc9e78 ebc32ce0 ebfc9e40 00000000 00000029 00000003</span><br><span class="line">[   28.128002] Call Trace:</span><br><span class="line">[   28.128002]  [&lt;c0350ad4&gt;] do_page_fault+0x1f4/0x4b0</span><br><span class="line">[   28.128002]  [&lt;c034df54&gt;] error_code+0x30/0x38</span><br><span class="line">[   28.128002]  [&lt;c01da35f&gt;] clear_user+0x2f/0x50   </span><br><span class="line">[   28.128002]  [&lt;c01480d4&gt;] load_elf_binary+0xae4/0xc30    </span><br><span class="line">[   28.128002]  [&lt;c01094d1&gt;] search_binary_handler+0x1e1/0x2e0  </span><br><span class="line">[   28.128002]  [&lt;c01097b4&gt;] do_execve_common+0x1e4/0x280   </span><br><span class="line">[   28.128002]  [&lt;c000a9c2&gt;] sys_execve+0x52/0x80   </span><br><span class="line">[   28.128002]  [&lt;c035443e&gt;] ptregs_execve+0x12/0x18    </span><br><span class="line">[   28.128002]  [&lt;c034dc3d&gt;] syscall_call+0x7/0x7   </span><br><span class="line">[   28.128002]  [&lt;c000933f&gt;] kernel_execve+0x1f/0x30    </span><br><span class="line">[   28.128002]  [&lt;c000424e&gt;] init_post+0xde/0x130   </span><br><span class="line">[   28.128002]  [&lt;c057d638&gt;] kernel_init+0x160/0x18f    </span><br><span class="line">[   28.128002]  [&lt;c0354526&gt;] kernel_thread_helper+0x6/0x10  </span><br><span class="line">[   28.128002] Code: 89 f2 89 f8 81 e2 00 f0 ff ff 25 ff 0f 00 00 89 54 24 0c 89 44 24 10 8b 44 24 0c 8b 54 24 10 0f ac d0 0c 89 44 24 0c 8b 44 24 0c &lt;c1&gt; ea 0c 89 54 24 10 c1 e0 05 03 44 24 20 e8 b3 90 ff ff 8b 54 </span><br><span class="line">......</span><br></pre></td></tr></table></figure><a id="more"></a>


<p>此类日志大量重复，每个重复的日志段不同的地方在于开头部分的进程名, 如:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NMI watchdog: BUG: soft lockup - CPU<span class="comment">#0 stuck for 23s  [sh:7422]</span></span><br><span class="line">...</span><br><span class="line">NMI watchdog: BUG: soft lockup - CPU<span class="comment">#0 stuck for 21s  [java:12148]</span></span><br><span class="line">...</span><br><span class="line">NMI watchdog: BUG: soft lockup - CPU<span class="comment">#0 stuck for 23s  [zabbix_agentd:2118]</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>除开头部分以外，剩余部分是内核代码函数调用栈，以及各个cpu寄存器此刻保存的值。</p>
<p>报错看上去像是cpu因为某些原因导致了死锁。根据以往经验，kernel问题导致的宕机会被kdump捕捉而生成一个core文件，kdump服务目前线上服务器在初始化的时候会统一开启，被kdump捕获到的core文件保存的是宕机那一刻服务器的完整内存数据，用很多工具可以分析该core文件(如crash <a href="https://www.ibm.com/developerworks/cn/linux/l-cn-dumpanalyse/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/linux/l-cn-dumpanalyse/index.html</a> 使用crash能较为完整的还原宕机那一刻的场景) ，但是目前的问题在于，该vm只是假死的状态(尚能ping通)，并未宕机。所以在和业务方确认并重启vm后，vm上并无core文件保留。</p>
<p>   此时该如何分析问题？这里提供一个思路，我们知道kernel日志都是linux内核代码打印的(最简单的比如调用c的print()) ，报错中的这类行: </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NMI watchdog: BUG: soft lockup - CPU</span><br></pre></td></tr></table></figure>
<p>有很大概率能在linux代码里找到。那么在哪能找到到Linux代码呢？linux本机自带，不过最方便的方法，是直接在github上查找，当前服务器的内核版本对应的github仓库:<a href="https://github.com/ayufan-pine64/linux-3.10，在该仓库内搜索&quot;BUG" target="_blank" rel="noopener">https://github.com/ayufan-pine64/linux-3.10，在该仓库内搜索&quot;BUG</a>: soft lockup”:<br><img src="github.png" alt><br>可以看待该报错出现在watchdog.c文件的第422行，点开该文件能看到报错所在函数的详情。</p>
<p>虽然找到了代码的对应位置，然而linux内核代码阅读难度很高，且各种调用/宏定义错综复杂，涉及到硬件的部分更是要查无数硬件的开发手册，此时又该如何分析？ 根据我的经验，如果是从分析问题的角度去追踪内核函数调用，难度远低于从头硬啃内核代码。第一是因为内核代码的每个函数都有详尽的注释，很多时候不需要看函数的具体实现就能明白函数功能，第二是如果如果对操作系统的一些基本概念有较深刻的理解(中断，任务调度，上下文切换等)，问题排查起来会事半功倍。以下是我的分析过程:</p>
<p>首先报错对应的函数是 watchdog_timer_fn()，这里贴出函数中的关键部分(……为略去部分):</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/* watchdog kicker <span class="built_in">functions</span> */</span><br><span class="line">static enum hrtimer_restart watchdog_timer_fn(struct hrtimer *hrtimer)</span><br><span class="line">&#123;</span><br><span class="line">        unsigned long touch_ts = __this_cpu_read(watchdog_touch_ts);</span><br><span class="line">        ......</span><br><span class="line">        int duration;</span><br><span class="line">        ......</span><br><span class="line">        /* check <span class="keyword">for</span> a softlockup</span><br><span class="line">         * This is <span class="keyword">done</span> by making sure a high priority task is</span><br><span class="line">         * being scheduled.  The task touches the watchdog to</span><br><span class="line">         * indicate it is getting cpu time.  If it hasn<span class="string">'t then</span></span><br><span class="line"><span class="string">         * this is a good indication some task is hogging the cpu</span></span><br><span class="line"><span class="string">         */</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        duration = is_softlockup(touch_ts);</span></span><br><span class="line"><span class="string">        if (unlikely(duration)) &#123;</span></span><br><span class="line"><span class="string">                /*</span></span><br><span class="line"><span class="string">                 * If a virtual machine is stopped by the host it can look to</span></span><br><span class="line"><span class="string">                 * the watchdog like a soft lockup, check to see if the host</span></span><br><span class="line"><span class="string">                 * stopped the vm before we issue the warning</span></span><br><span class="line"><span class="string">                 */</span></span><br><span class="line"><span class="string">                if (kvm_check_and_clear_guest_paused())</span></span><br><span class="line"><span class="string">                        return HRTIMER_RESTART;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                /* only warn once */</span></span><br><span class="line"><span class="string">                if (__this_cpu_read(soft_watchdog_warn) == true)</span></span><br><span class="line"><span class="string">                        return HRTIMER_RESTART;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                printk(KERN_EMERG "BUG: soft lockup - CPU#%d stuck for %us! [%s:%d]\n",</span></span><br><span class="line"><span class="string">                        smp_processor_id(), duration,</span></span><br><span class="line"><span class="string">                        current-&gt;comm, task_pid_nr(current));</span></span><br><span class="line"><span class="string">        &#125; </span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        ......</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        return HRTIMER_RESTART;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure>
<p>首先要明白2个概念:</p>
<ol>
<li>代码中反复提到的watchdog，watchdog可以简单理解为linux会为每个cpu注册一个watchdog线程，这个线程最重要的功能是会定期执行一些检测函数检测cpu的状态，其中的功能就包括检测cpu死锁，我们可以在linux上看到watchdog线程，比如4核的vm:<br><img src="ps.png" alt></li>
</ol>
<p>2.时钟中断，可以简单理解为linux内核的定时任务的实现方式，二实现计时功能的是一个计时器(物理上的)，计时器溢出时，就向CPU申请中断，如果允许响应中断，CPU就会找到对应的中断响应函数执行(中断服务程序)，计时器重新归零</p>
<p>搞明白这两点后，通过该函数的注释 /* watchdog kicker functions */ 以及函数名 watchdog_timer_fn可以看出，这是一个属于watchdog的时钟中断函数，定时执行，具体多久执行一次可以先不管。</p>
<p>函数第4行首先执行__this_cpu_read(watchdog_touch_ts)，作用是从cpu的cache中取出watchdog_touch_ts变量的值，而这个值是由watchdog线程定期更新(后文会分析)</p>
<p>第8行开始又是一段很重要的注释，注释说明了死锁的检测原理: 通过watchdog让cpu定期去调度一个高优先级的任务，如果该任务在一定时间内得不到调度，则说明了cpu正在被占用。我们知道linux内核是抢占调度，若高优先级的任务长时间无法抢占cpu，则说明cpu出现异常(如抢占被关闭)</p>
<p>15行开始是具体的检测过程，is_softlockup函数以及相关定义如下:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">int __read_mostly watchdog_thresh = 10;</span><br><span class="line">......</span><br><span class="line">static int is_softlockup(unsigned long touch_ts)</span><br><span class="line">&#123;</span><br><span class="line">        unsigned long now = get_timestamp();</span><br><span class="line"></span><br><span class="line">        /* Warn about unreasonable delays: */</span><br><span class="line">        <span class="keyword">if</span> (time_after(now, touch_ts + get_softlockup_thresh()))</span><br><span class="line">                <span class="built_in">return</span> now - touch_ts;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br><span class="line">......</span><br><span class="line">static int get_softlockup_thresh(void)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="built_in">return</span> watchdog_thresh * 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>is_softlockup函数首先获得当前时间戳，然后判断传入的watchdog_touch_ts变量加上watchdog_thresh * 2=20(秒)的值是否小于当前时间戳，time_after是一个宏定义如下:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#define time_after(a,b)         \ </span></span><br><span class="line">        (typecheck(unsigned long, a) &amp;&amp; \</span><br><span class="line">         typecheck(unsigned long, b) &amp;&amp; \</span><br><span class="line">         ((long)((b) - (a)) &lt; 0))</span><br></pre></td></tr></table></figure>
<p>所以is_softlockup的逻辑很简单，就是查看watchdog_touch_ts变量在最近20秒的时间内是否被watchdog更新过。若在20秒内未被更新，则返回now - touch_ts(这就是我们再kernel log中看到的具体秒数)<br>此时回到watchdog_timer_fn时钟中断函数，第16行判断is_softlockup返回值，如果不为   0(watchdog_touch_ts在20秒未被更新，就说明高优先级线程在20秒内得不到调度，此时发生死锁) 进入if条件，22行考虑了宿主机关闭虚拟机导致类似死锁的情况，26行考虑了cpu cache中的soft_watchdog_warn值为true的情况，这两种情况下直接重置时钟，不做处理。最终在29行之后打印了我们最初看到的kernel log和调用栈。</p>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论:"></a>结论:</h4><p>通过上述分析不难得出结论，某个内核任务正在运行且长时间(20s)未释放cpu或者直接关闭了cpu抢占，内核的检测线程watchdog发现了该情况，并向kernel日志输出”系统正在发生死锁”的信息，此时系统非常缓慢。那么具体是哪个任务在占用cpu不放呢，比较遗憾的是我们当前vm的rsyslog配置中，kernel日志只输出到console而未保存在本地，而console log会在每次vm启动后刷新，无法进行完整分析。另外由于openstack宿主机的cpu有2.5倍的超售设置(腾讯云也一样)，相当于最坏情况下每2.5个vm上的cpu共享一个宿主机物理cpu，那么这个占用cpu不释放的任务，也完全有可能在其他的vm上.<br>       linux代码里只能看到死锁发生的根本原因，官方并没有给出死锁的实际触发场景，查阅相关资料：<br>       vmvare :  high levels of overcommitment<br>       redhat :  it could because of a very high system load<br>       均说明(软)死锁的触发和系统负载有很大关系，特别是在虚拟环境下。此时我分析了宿主机BJ-YZ-C05-COMPUTE03.inner-dmall.com的负载情况:  </p>
<ol>
<li><p>cpu使用长期保持在70%以上，系统load长期保持在30以上<br><img src="load.png" alt></p>
</li>
<li><p>vcpu使用量几乎达到极限(每个宿主机会保留2个物理cpu给系统本身，所以可以使用的最大vcpu数为110):</p>
</li>
</ol>
<p>基本可以判定，此次故障是由于宿主机负载过高引起，发生故障的vm上的vcpu 0未能及时抢占到物理cpu而发生死锁(这里推测可能是共享该物理cpu的另一个vm的程序长时间占用或者宿主机用于负载较高未能及时处理调度任务)</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案:"></a>解决方案:</h3><p>可以考虑调整内核kernel.watchdog_thresh的值，比如把20s的检测阈值提高到40s，但这个方法治标不治本。最好的方法，是迁移宿主机上的高负载vm到之后扩容的较为空闲的宿主机上，以降低整体负载，减少软死锁的发生概率。并且修改全局的rsyslog配置，将kernel log在本地保存，方便后续排查问题</p>
<h4 id="补充"><a href="#补充" class="headerlink" title="补充:"></a>补充:</h4><p>上面的代码分析部分没有详细说明watchdog具体是怎么注册，以及watchdog_touch_ts是如何被更新的，这里给出相关函数和结构体，感兴趣的同学可以自行分析:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">static struct smp_hotplug_thread watchdog_threads;</span><br><span class="line">void __init lockup_detector_init(void);</span><br><span class="line">static void set_sample_period(void)</span><br><span class="line">static void watchdog(unsigned int cpu)</span><br><span class="line">static void watchdog_enable(unsigned int cpu)</span><br></pre></td></tr></table></figure>
<p>(建议clone整个linux代码到本地，并使用vim+ctags，可以直接在vim使用ctrl + ]跳转至函数定义，方便查看)</p>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考:"></a>参考:</h4><p><a href="https://www.kernel.org/doc/Documentation/lockup-watchdogs.txt" target="_blank" rel="noopener">https://www.kernel.org/doc/Documentation/lockup-watchdogs.txt</a><br><a href="https://blog.seibert-media.com/2018/01/04/log-book-linux-cpu-lockups" target="_blank" rel="noopener">https://blog.seibert-media.com/2018/01/04/log-book-linux-cpu-lockups</a></p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2019/10/27/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><a id="more"></a>






<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
